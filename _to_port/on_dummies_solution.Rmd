---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.11.5
---

$\newcommand{L}[1]{\| #1 \|}\newcommand{VL}[1]{\L{ \vec{#1} }}\newcommand{R}[1]{\operatorname{Re}\,(#1)}\newcommand{I}[1]{\operatorname{Im}\, (#1)}$

<!-- vim: ft=rst -->
## Modeling groups with dummy variables exercise

### Introduction and definitions

```{python}
#: Import numerical and plotting libraries
import numpy as np
# Print to four digits of precision
np.set_printoptions(precision=4, suppress=True)
import numpy.linalg as npl
import matplotlib.pyplot as plt
```

We return to the psychopathy of students from Berkeley and MIT.

We get psychopathy questionnaire scores from another set of 5 students from
Berkeley:

```{python}
#: Psychopathy scores from UCB students
ucb_psycho = np.array([2.9277, 9.7348, 12.1932, 12.2576, 5.4834])
```

We do the same for another set of 5 students from MIT:

```{python}
#: Psychopathy scores from MIT students
mit_psycho = np.array([7.2937, 11.1465, 13.5204, 15.053, 12.6863])
```

Concatenate these into a `psychopathy` vector:

```{python}
#: Concatenate UCB and MIT student scores
psychopathy = np.concatenate((ucb_psycho, mit_psycho))
```

We will use the general linear model to a two-level (UCB, MIT) single factor
(college) analysis of variance on these data.

Our model is that the Berkeley student data are drawn from some distribution
with a mean value that is characteristic for Berkeley: $y_i = \mu_{Berkeley} +
e_i$ where $i$ corresponds to a student from Berkeley.  There is also a
characteristic but possibly different mean value for MIT: $\mu_{MIT}$:

$$
\newcommand{\yvec}{\vec{y}}
\newcommand{\xvec}{\vec{x}}
\newcommand{\evec}{\vec{\varepsilon}}
\newcommand{Xmat}{\boldsymbol X}
\newcommand{\bvec}{\vec{\beta}}
\newcommand{\bhat}{\hat{\bvec}}
\newcommand{\yhat}{\hat{\yvec}}

y_i = \mu_{Berkeley} + e_i  \space\mbox{if}\space 1 \le i \le 5

y_i = \mu_{MIT} + e_i \space\mbox{if}\space 6 \le i \le 10
$$

We saw in [introduction to the general linear model](https://matthew-brett.github.io/teaching/glm_intro.html) that we can encode this
group membership with dummy variables.  There is one dummy variable for each
group.  The dummy variables are *indicator* variables, in that they have 1 in
the row corresponding to observations in the group, and zero elsewhere.

We will compile a design matrix $\Xmat$ and use the matrix formulation of the
general linear model to do estimation and testing:

$$
\yvec = \Xmat \bvec + \evec
$$

# ANOVA design

Create the design matrix for this ANOVA, with dummy variables corresponding to the UCB and MIT student groups:

```{python}
#- Create design matrix for UCB / MIT ANOVA
Y = psychopathy
n = len(Y)
X = np.zeros((n, 2))
X[:5, 0] = 1  # UCB indicator
X[5:, 1] = 1  # MIT indicator
X
```

Remember that, when $\Xmat^T \Xmat$ is invertible, our least-squares parameter
estimates $\bhat$ are given by:

$$
\bhat = (\Xmat^T \Xmat)^{-1} \Xmat^T \yvec
$$

First calculate $\Xmat^T \Xmat$. Are the columns of this design orthogonal?

```{python}
#- Calculate transpose of design with itself.
#- Are the design columns orthogonal?
X.T.dot(X)
```

Calculate the inverse of $\Xmat^T \Xmat$.

```{python}
#- Calculate inverse of transpose of design with itself.
iXtX = npl.inv(X.T.dot(X))
iXtX
```

Now calculate the second half of $(\Xmat^T \Xmat)^{-1} \Xmat^T \yvec$:
$\vec{p} = \Xmat^T \yvec$.

```{python}
#- Calculate transpose of design matrix multiplied by data
XtY = X.T.dot(Y)
```

Now calculate $\bhat$ using $(\Xmat^T \Xmat)^{-1} \Xmat^T \yvec$:

```{python}
#- Calculate beta vector
B = iXtX.dot(XtY)
B
```

Compare this vector to the means of the values in `ucb_psycho` and
`mit_psycho`:

```{python}
#- Compare beta vector to means of each group
ucb_psycho.mean()
mit_psycho.mean()
```

# Hypothesis testing with contrasts

Remember the student’s t statistic from the general linear model :

$$
\newcommand{\cvec}{\vec{c}}
t = \frac{\cvec^T \bhat}
{\sqrt{\hat{\sigma}^2 \cvec^T (\Xmat^T \Xmat)^+ \cvec}}
$$

Let’s consider the top half of the t statistic, $c^T \bhat$.

Our hypothesis is that the mean psychopathy score for MIT students,
$\mu_{MIT}$, is higher than the mean psychopathy score for Berkeley students,
$\mu_{Berkeley}$.  What contrast vector $\cvec$ do we need to apply to $\bhat$
to express the difference between these means?  Apply this contrast vector to
$\bhat$ to get the top half of the t statistic.

```{python}
#- Contrast vector to express difference between UCB and MIT
#- Resulting value will be high and positive when MIT students have
#- higher psychopathy scores than UCB students
c = np.array([-1, 1])
top_of_t = c.dot(B)
top_of_t
```

Now the bottom half of the t statistic.  Remember this is
$\sqrt{\hat{\sigma}^2 \cvec^T (\Xmat^T \Xmat)^+ \cvec}$.

First we generate $\hat{\sigma^2}$ from the residuals of the model.

Calculate the fitted values and the residuals given the $\bhat$ that you have
already.

```{python}
#- Calculate the fitted and residual values
fitted = X.dot(B)
residuals = Y - fitted
```

We want an unbiased variance estimate for $\hat\sigma^2$.  See the [worked
example of GLM](https://github.com/bic-berkeley/psych-214-fall-2014/mean_test_example.html) page and the [unbiased variance estimate](https://bic-berkeley.github.io/psych-214-fall-2016/hypothesis_tests.html#unbiased-variance) section for
details.

The general rule is that we divide the sum of squares by $n - m$ where $m$ is
the number of *independent* columns in the design matrix.  Specifically, $m$
is the [matrix rank](http://matthew-brett.github.io/teaching/matrix_rank.html) of the design $\Xmat$.  $m$ can also be called the
*degrees of freedom of the design*.  $n - m$ is the *degrees of freedom of the
error* (see [unbiased variance estimate](https://bic-berkeley.github.io/psych-214-fall-2016/hypothesis_tests.html#unbiased-variance)).

```{python}
#- Calculate the degrees of freedom consumed by the design
m = npl.matrix_rank(X)
#- Calculate the degrees of freedom of the error
df_error = n - m
df_error
```

Calculate the unbiased *variance* estimate $\hat{\sigma^2}$ by dividing the
sums of squares of the residuals by the degrees of freedom of the error.

```{python}
#- Calculate the unbiased variance estimate
var_hat = np.sum(residuals ** 2) / df_error
var_hat
```

Now the calculate second part of the t statistic denominator,  $\cvec^T (\Xmat^T
\Xmat)^+ \cvec$. You already know that $\Xmat^T \Xmat$ is invertible, and you
have its inverse above, so you can use the inverse instead of the more general
pseudo-inverse.

```{python}
#- Calculate c (X.T X)^-1 c.T
c_iXtX_ct = c.dot(npl.inv(X.T.dot(X))).dot(c)
c_iXtX_ct
```

Now, what is our t-value ?

```{python}
tstat = top_of_t / np.sqrt(var_hat*c.T.dot(iXtX).dot(c))
tstat
```

Is this significant ? Use the `stats` module from `scipy` to create a
t-distribution with `df_error` (degrees of freedom of the error).  See the
`t_stat` function in [introduction to the general linear model](https://matthew-brett.github.io/teaching/glm_intro.html) for
inspiration:

```{python}
#- Use scipy.stats to test if your t-test value is significant.
import scipy.stats as sst
tdistrib = sst.t(df_error)
# 1 - cumulative density function (P(x <= t)
1. - tdistrib.cdf(tstat)
# This is the same as the "survival function"
tdistrib.sf(tstat)
```

# Hypothesis testing: F-tests

Imagine we have also measured the clammy score for the Berkeley and MIT
students.

```{python}
#: Clamminess of handshake for UCB and MIT students
clammy = np.array([2.6386, 9.6094, 8.3379, 6.2871, 7.2775, 2.4787,
                   8.6037, 12.8713, 10.4906, 5.6766])
```

We want to test whether the clammy score is useful in explaining
the psychopathy data, over and above the students’ college affiliation.

To do this, we will use an [F test](https://bic-berkeley.github.io/psych-214-fall-2016/hypothesis_tests.html#f-tests).

An F-test compares a *full model* $\Xmat_f$ with a *reduced model* $\Xmat_r$.

In our case, $\Xmat_f$ is the model containing the `clammy` regressor, as
well as the two dummy columns for the UCB and MIT group means.

$\Xmat_r$ is our original model, that only contains the dummy columns for the
UCB and MIT group means.

We define $SSR(\Xmat_r)$ and $SSR(\Xmat_f)$ as in [hypothesis tests](https://bic-berkeley.github.io/psych-214-fall-2016/hypothesis_tests.html).
These are the Sums of Squares of the Residuals of the reduced and full model
respectively.

$$
\bhat_r = \Xmat_r^+ \yvec \\
\hat\evec_r = \yvec - \Xmat_r \bhat_r \\
SSR(\Xmat_r) = \hat\evec_r^T \hat\evec_r \\

\bhat_f = \Xmat_f^+ \yvec \\
\hat\evec_f = \yvec - \Xmat_f \bhat_f \\
SSR(\Xmat_f) = \hat\evec_f^T \hat\evec_f
$$

You can calculate the F statistic for adding the `clammy` regressor, by
using these calculations and the formula for the F-test in [F tests](https://bic-berkeley.github.io/psych-214-fall-2016/hypothesis_tests.html#f-tests).

<!-- vim:ft=rst -->
<!-- Course -->
<!-- BIC -->
<!-- Python distributions -->
<!-- Version control -->
<!-- Editors -->
<!-- Python and common libraries -->
<!-- IPython -->
<!-- Virtualenv and helpers -->
<!-- Pypi and packaging -->
<!-- Mac development -->
<!-- Windows development -->
<!-- Nipy and friends -->
<!-- FMRI datasets -->
<!-- Languages -->
<!-- Imaging software -->
<!-- Installation -->
<!-- Tutorials -->
<!-- MB tutorials -->
<!-- Ideas -->
<!-- Psych-214 -->
<!-- People -->
<!-- Licenses -->
<!-- Neuroimaging stuff -->
<!-- OpenFMRI projects -->
<!-- Unix -->
<!-- Substitutions -->
